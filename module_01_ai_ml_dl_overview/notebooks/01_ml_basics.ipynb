{
 "cells": [
 {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
 "# Machine Learning Basics\n",
 "\n",
 "## Overview\n",
 "This notebook introduces fundamental machine learning concepts using scikit-learn. We'll cover:\n",
 "- Basic ML workflow\n",
 "- Classification (predicting categories)\n",
 "- Regression (predicting continuous values)\n",
 "- Model evaluation\n",
 "\n",
 "## Setup\n",
 "Run this in Google Colab or local Jupyter environment."
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Install required packages (uncomment if needed)\n",
 "# !pip install scikit-learn pandas matplotlib seaborn numpy\n",
 "\n",
 "import numpy as np\n",
 "import pandas as pd\n",
 "import matplotlib.pyplot as plt\n",
 "import seaborn as sns\n",
 "from sklearn.model_selection import train_test_split\n",
 "from sklearn.preprocessing import StandardScaler\n",
 "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
 "from sklearn.tree import DecisionTreeClassifier\n",
 "from sklearn.ensemble import RandomForestClassifier\n",
 "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
 "from sklearn.metrics import mean_squared_error, r2_score\n",
 "from sklearn.datasets import load_iris, load_diabetes, make_classification\n",
 "\n",
 "# Set style\n",
 "sns.set_style('whitegrid')\n",
 "plt.rcParams['figure.figsize'] = (10, 6)\n",
 "\n",
 "print(\" Libraries imported successfully!\")"
 ]
 },
 {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
 "## Part 1: Classification - Iris Dataset\n",
 "\n",
 "### What is Classification?\n",
 "Classification is predicting which category (class) an item belongs to.\n",
 "\n",
 "**Example:** Given flower measurements, predict the species (Setosa, Versicolor, or Virginica)"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Load the Iris dataset\n",
 "iris = load_iris()\n",
 "X = iris.data # Features: sepal length, sepal width, petal length, petal width\n",
 "y = iris.target # Target: species (0, 1, or 2)\n",
 "\n",
 "# Create a DataFrame for better visualization\n",
 "df = pd.DataFrame(X, columns=iris.feature_names)\n",
 "df['species'] = pd.Categorical.from_codes(y, iris.target_names)\n",
 "\n",
 "print(\"Dataset shape:\", df.shape)\n",
 "print(\"\\nFirst few rows:\")\n",
 "df.head()"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Visualize the data\n",
 "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
 "\n",
 "# Scatter plot\n",
 "for species in iris.target_names:\n",
 " subset = df[df['species'] == species]\n",
 " axes[0].scatter(subset['petal length (cm)'], subset['petal width (cm)'], \n",
 " label=species, alpha=0.7, s=100)\n",
 "axes[0].set_xlabel('Petal Length (cm)')\n",
 "axes[0].set_ylabel('Petal Width (cm)')\n",
 "axes[0].set_title('Iris Dataset - Petal Dimensions')\n",
 "axes[0].legend()\n",
 "axes[0].grid(True, alpha=0.3)\n",
 "\n",
 "# Distribution plot\n",
 "df.groupby('species')['petal length (cm)'].plot(kind='kde', ax=axes[1], legend=True)\n",
 "axes[1].set_xlabel('Petal Length (cm)')\n",
 "axes[1].set_title('Distribution of Petal Length by Species')\n",
 "axes[1].grid(True, alpha=0.3)\n",
 "\n",
 "plt.tight_layout()\n",
 "plt.show()\n",
 "\n",
 "print(\"\\n Notice how different species cluster together!\")"
 ]
 },
 {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
 "### The Machine Learning Workflow\n",
 "\n",
 "```\n",
 "1. Split data → Train/Test sets\n",
 "2. Train model → Learn patterns from training data\n",
 "3. Evaluate → Test on unseen data\n",
 "4. Predict → Use model for new data\n",
 "```"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Step 1: Split the data (80% train, 20% test)\n",
 "X_train, X_test, y_train, y_test = train_test_split(\n",
 " X, y, test_size=0.2, random_state=42\n",
 ")\n",
 "\n",
 "print(f\"Training samples: {len(X_train)}\")\n",
 "print(f\"Testing samples: {len(X_test)}\")\n",
 "print(\"\\n We train on 80% and test on 20% to evaluate performance on unseen data\")"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Step 2: Train a Logistic Regression model\n",
 "model = LogisticRegression(max_iter=200)\n",
 "model.fit(X_train, y_train)\n",
 "\n",
 "print(\" Model trained!\")\n",
 "print(\"\\n The model has learned patterns from the training data\")"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Step 3: Evaluate the model\n",
 "y_pred = model.predict(X_test)\n",
 "\n",
 "accuracy = accuracy_score(y_test, y_pred)\n",
 "print(f\"Accuracy: {accuracy:.2%}\")\n",
 "print(\"\\nClassification Report:\")\n",
 "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Visualize confusion matrix\n",
 "cm = confusion_matrix(y_test, y_pred)\n",
 "plt.figure(figsize=(8, 6))\n",
 "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
 " xticklabels=iris.target_names, \n",
 " yticklabels=iris.target_names)\n",
 "plt.title('Confusion Matrix')\n",
 "plt.ylabel('True Label')\n",
 "plt.xlabel('Predicted Label')\n",
 "plt.show()\n",
 "\n",
 "print(\"\\n Diagonal elements = correct predictions\")\n",
 "print(\" Off-diagonal = misclassifications\")"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Step 4: Make predictions on new data\n",
 "new_flower = np.array([[5.1, 3.5, 1.4, 0.2]]) # Example measurements\n",
 "prediction = model.predict(new_flower)\n",
 "probability = model.predict_proba(new_flower)\n",
 "\n",
 "print(f\"Predicted species: {iris.target_names[prediction[0]]}\")\n",
 "print(\"\\nProbabilities:\")\n",
 "for i, species in enumerate(iris.target_names):\n",
 " print(f\" {species}: {probability[0][i]:.2%}\")"
 ]
 },
 {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
 "## Part 2: Comparing Different Classifiers\n",
 "\n",
 "Let's compare multiple algorithms!"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Define multiple models\n",
 "models = {\n",
 " 'Logistic Regression': LogisticRegression(max_iter=200),\n",
 " 'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
 " 'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
 "}\n",
 "\n",
 "# Train and evaluate each model\n",
 "results = {}\n",
 "for name, model in models.items():\n",
 " model.fit(X_train, y_train)\n",
 " y_pred = model.predict(X_test)\n",
 " accuracy = accuracy_score(y_test, y_pred)\n",
 " results[name] = accuracy\n",
 " print(f\"{name}: {accuracy:.2%}\")\n",
 "\n",
 "# Visualize comparison\n",
 "plt.figure(figsize=(10, 6))\n",
 "plt.bar(results.keys(), results.values(), color=['#3498db', '#e74c3c', '#2ecc71'])\n",
 "plt.ylabel('Accuracy')\n",
 "plt.title('Model Comparison')\n",
 "plt.ylim([0.9, 1.0])\n",
 "for i, (name, acc) in enumerate(results.items()):\n",
 " plt.text(i, acc + 0.005, f'{acc:.2%}', ha='center', fontweight='bold')\n",
 "plt.grid(axis='y', alpha=0.3)\n",
 "plt.show()"
 ]
 },
 {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
 "## Part 3: Regression - Predicting Continuous Values\n",
 "\n",
 "### What is Regression?\n",
 "Regression predicts continuous numerical values.\n",
 "\n",
 "**Example:** Predicting house prices, stock prices, temperature, etc."
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Load diabetes dataset (predicting disease progression)\n",
 "diabetes = load_diabetes()\n",
 "X_reg = diabetes.data\n",
 "y_reg = diabetes.target\n",
 "\n",
 "print(f\"Dataset shape: {X_reg.shape}\")\n",
 "print(f\"Features: {diabetes.feature_names}\")\n",
 "print(f\"Target: Disease progression (continuous value)\")"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Split data\n",
 "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
 " X_reg, y_reg, test_size=0.2, random_state=42\n",
 ")\n",
 "\n",
 "# Train Linear Regression model\n",
 "reg_model = LinearRegression()\n",
 "reg_model.fit(X_train_reg, y_train_reg)\n",
 "\n",
 "# Make predictions\n",
 "y_pred_reg = reg_model.predict(X_test_reg)\n",
 "\n",
 "# Evaluate\n",
 "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
 "rmse = np.sqrt(mse)\n",
 "r2 = r2_score(y_test_reg, y_pred_reg)\n",
 "\n",
 "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
 "print(f\"R² Score: {r2:.3f}\")\n",
 "print(\"\\n R² Score: 1.0 = perfect, 0.0 = baseline\")"
 ]
 },
 {
 "cell_type": "code",
 "execution_count": null,
 "metadata": {},
 "outputs": [],
 "source": [
 "# Visualize predictions vs actual\n",
 "plt.figure(figsize=(10, 6))\n",
 "plt.scatter(y_test_reg, y_pred_reg, alpha=0.6, s=100)\n",
 "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
 " [y_test_reg.min(), y_test_reg.max()], \n",
 " 'r--', lw=2, label='Perfect Prediction')\n",
 "plt.xlabel('Actual Values')\n",
 "plt.ylabel('Predicted Values')\n",
 "plt.title('Regression: Predicted vs Actual')\n",
 "plt.legend()\n",
 "plt.grid(True, alpha=0.3)\n",
 "plt.show()\n",
 "\n",
 "print(\"\\n Points closer to the red line = better predictions\")"
 ]
 },
 {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
 "## Key Concepts Summary\n",
 "\n",
 "### Classification vs Regression\n",
 "\n",
 "| Aspect | Classification | Regression |\n",
 "|--------|---------------|------------|\n",
 "| **Output** | Categories (discrete) | Numbers (continuous) |\n",
 "| **Example** | Spam/Not Spam | House Price |\n",
 "| **Metrics** | Accuracy, F1-Score | MSE, R² |\n",
 "| **Algorithms** | Logistic Regression, Decision Trees | Linear Regression, SVR |\n",
 "\n",
 "### ML Workflow\n",
 "1. **Load Data** → Understand your dataset\n",
 "2. **Split Data** → Train/Test sets\n",
 "3. **Train Model** → Learn patterns\n",
 "4. **Evaluate** → Measure performance\n",
 "5. **Predict** → Use on new data\n",
 "\n",
 "### Key Takeaways\n",
 "- Machine Learning learns patterns from data\n",
 "- Always split data to evaluate on unseen examples\n",
 "- Different algorithms have different strengths\n",
 "- Visualization helps understand data and results"
 ]
 },
 {
 "cell_type": "markdown",
 "metadata": {},
 "source": [
 "## Exercise\n",
 "\n",
 "Try modifying the code:\n",
 "1. Change the train/test split ratio (e.g., 70/30)\n",
 "2. Try different features from the Iris dataset\n",
 "3. Experiment with model parameters\n",
 "4. Create visualizations for other feature combinations\n",
 "\n",
 "## Next Steps\n",
 "- **Next Notebook:** Generative AI Demo with HuggingFace\n",
 "- **Module 2:** Mathematical Foundations\n",
 "- **Module 3:** Neural Networks from Scratch"
 ]
 }
 ],
 "metadata": {
 "kernelspec": {
 "display_name": "Python 3",
 "language": "python",
 "name": "python3"
 },
 "language_info": {
 "codemirror_mode": {
 "name": "ipython",
 "version": 3
 },
 "file_extension": ".py",
 "mimetype": "text/x-python",
 "name": "python",
 "nbconvert_exporter": "python",
 "pygments_lexer": "ipython3",
 "version": "3.10.0"
 }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
