{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics\n\nLearn PyTorch fundamentals for building neural networks.\\n\\n## Topics\\n- Tensors\\n- Autograd\\n- Building models\\n- Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nprint(f'PyTorch version: {torch.__version__}')\\nprint(f'CUDA available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensors\\n\\nTensors are the fundamental data structure in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors\\nx = torch.tensor([1, 2, 3, 4, 5])\\nprint(f'1D tensor: {x}')\\nprint(f'Shape: {x.shape}')\\nprint(f'Data type: {x.dtype}')\\n\\n# 2D tensor\\nmatrix = torch.tensor([[1, 2], [3, 4], [5, 6]])\\nprint(f'\\\\n2D tensor:\\\\n{matrix}')\\nprint(f'Shape: {matrix.shape}')\\n\\n# Random tensors\\nrand_tensor = torch.randn(3, 4)\\nprint(f'\\\\nRandom tensor:\\\\n{rand_tensor}')\\n\\n# Zeros and ones\\nzeros = torch.zeros(2, 3)\\nones = torch.ones(2, 3)\\nprint(f'\\\\nZeros:\\\\n{zeros}')\\nprint(f'\\\\nOnes:\\\\n{ones}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations\\na = torch.tensor([1.0, 2.0, 3.0])\\nb = torch.tensor([4.0, 5.0, 6.0])\\n\\nprint(f'Addition: {a + b}')\\nprint(f'Multiplication: {a * b}')\\nprint(f'Dot product: {torch.dot(a, b)}')\\n\\n# Matrix multiplication\\nA = torch.randn(3, 4)\\nB = torch.randn(4, 2)\\nC = torch.mm(A, B)  # or A @ B\\nprint(f'\\\\nMatrix multiplication shape: {C.shape}')\\n\\n# Reshaping\\nx = torch.randn(12)\\nreshaped = x.view(3, 4)\\nprint(f'\\\\nOriginal shape: {x.shape}')\\nprint(f'Reshaped: {reshaped.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autograd - Automatic Differentiation\\n\\nPyTorch's autograd automatically computes gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gradient tracking\\nx = torch.tensor([2.0], requires_grad=True)\\ny = x ** 2 + 3 * x + 1\\n\\nprint(f'x = {x.item()}')\\nprint(f'y = {y.item()}')\\n\\n# Compute gradients\\ny.backward()\\nprint(f'dy/dx = {x.grad.item()}')\\nprint(f'Expected (2*x + 3) = {2*x.item() + 3}')\\n\\n# Example: Linear regression\\nw = torch.tensor([1.0], requires_grad=True)\\nb = torch.tensor([0.0], requires_grad=True)\\n\\nx_data = torch.tensor([1.0, 2.0, 3.0, 4.0])\\ny_data = torch.tensor([2.0, 4.0, 6.0, 8.0])\\n\\n# Forward pass\\ny_pred = w * x_data + b\\nloss = ((y_pred - y_data) ** 2).mean()\\n\\nprint(f'\\\\nLoss: {loss.item():.4f}')\\n\\n# Backward pass\\nloss.backward()\\nprint(f'dL/dw: {w.grad.item():.4f}')\\nprint(f'dL/db: {b.grad.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Neural Networks\\n\\nUse `nn.Module` to define models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\\n    def __init__(self, input_size, hidden_size, output_size):\\n        super(SimpleNN, self).__init__()\\n        self.fc1 = nn.Linear(input_size, hidden_size)\\n        self.relu = nn.ReLU()\\n        self.fc2 = nn.Linear(hidden_size, output_size)\\n    \\n    def forward(self, x):\\n        x = self.fc1(x)\\n        x = self.relu(x)\\n        x = self.fc2(x)\\n        return x\\n\\n# Create model\\nmodel = SimpleNN(10, 20, 5)\\nprint(model)\\n\\n# Model parameters\\nprint(f'\\\\nNumber of parameters: {sum(p.numel() for p in model.parameters())}')\\n\\n# Forward pass\\nx = torch.randn(32, 10)  # batch of 32\\noutput = model(x)\\nprint(f'\\\\nInput shape: {x.shape}')\\nprint(f'Output shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\\n\\nComplete training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\\nfrom sklearn.model_selection import train_test_split\\n\\n# Generate dataset\\nX, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Convert to tensors\\nX_train = torch.FloatTensor(X_train)\\ny_train = torch.FloatTensor(y_train).unsqueeze(1)\\nX_test = torch.FloatTensor(X_test)\\ny_test = torch.FloatTensor(y_test).unsqueeze(1)\\n\\n# Create model\\nmodel = SimpleNN(20, 64, 1)\\ncriterion = nn.BCEWithLogitsLoss()\\noptimizer = optim.Adam(model.parameters(), lr=0.001)\\n\\n# Training loop\\nlosses = []\\nfor epoch in range(100):\\n    # Forward pass\\n    outputs = model(X_train)\\n    loss = criterion(outputs, y_train)\\n    \\n    # Backward pass\\n    optimizer.zero_grad()\\n    loss.backward()\\n    optimizer.step()\\n    \\n    losses.append(loss.item())\\n    \\n    if (epoch + 1) % 20 == 0:\\n        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\\n\\n# Plot loss\\nplt.plot(losses)\\nplt.xlabel('Epoch')\\nplt.ylabel('Loss')\\nplt.title('Training Loss')\\nplt.grid(True)\\nplt.show()\\n\\n# Evaluate\\nmodel.eval()\\nwith torch.no_grad():\\n    test_outputs = model(X_test)\\n    predictions = (torch.sigmoid(test_outputs) > 0.5).float()\\n    accuracy = (predictions == y_test).float().mean()\\n    print(f'\\\\nTest Accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\\n\\n\u2705 Tensors and operations\\n\u2705 Autograd for automatic differentiation\\n\u2705 Building models with nn.Module\\n\u2705 Complete training loop\\n\u2705 Model evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}